{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, recall_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "df=pd.read_csv('C:\\\\Users\\\\PC\\\\Desktop\\\\train_set.csv')\n",
    "df_test=pd.read_csv('C:\\\\Users\\\\PC\\\\Desktop\\\\test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['auto_payment'].fillna(0, inplace=True)\n",
    "df['call_drops'].fillna(0, inplace=True)\n",
    "#Sıkıntılı olursa geri dön\n",
    "tenure_median = df['tenure'].median()\n",
    "df['tenure'] = df['tenure'].fillna(tenure_median)\n",
    "data_usage_median = df['data_usage'].median()\n",
    "df['data_usage'] = df['data_usage'].fillna(data_usage_median)\n",
    "monthly_charge_median = df['monthly_charge'].median()\n",
    "df['monthly_charge'] = df['monthly_charge'].fillna(monthly_charge_median)\n",
    "avg_values = df.groupby(\"service_type\")[\"avg_call_duration\"].transform(\"mean\")\n",
    "df[\"avg_call_duration\"] = df[\"avg_call_duration\"].fillna(avg_values)\n",
    "df[\"avg_call_duration\"] = df[\"avg_call_duration\"].fillna(0)\n",
    "roaming_usage_median = df['roaming_usage'].median()\n",
    "df['roaming_usage'] = df['roaming_usage'].fillna(roaming_usage_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['service_type'], drop_first=False)\n",
    "df.drop(['id', 'apps'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC score from 3-fold cross-validation: 0.9365698010131357\n"
     ]
    }
   ],
   "source": [
    "# Log dönüşümü uygulama\n",
    "for col in ['avg_top_up_count', 'monthly_charge', 'tenure', 'age']:\n",
    "    df[col] = np.log1p(df[col])  # log(1 + x) dönüşümünü uygula\n",
    "\n",
    "X = df.drop(columns=[\"churn\"])\n",
    "y = df[\"churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "model = XGBClassifier(random_state=42, scale_pos_weight=1, learning_rate=0.05, max_depth=5, n_estimators=100)\n",
    "cv_scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=3, scoring='roc_auc')\n",
    "\n",
    "print(f\"Average ROC AUC score from 3-fold cross-validation: {cv_scores.mean()}\")\n",
    "\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 8240\n",
      "True Negatives (TN): 1346820\n",
      "False Positives (FP): 231811\n",
      "False Negatives (FN): 13129\n",
      "F1 Score: 0.0630\n",
      "ROC AUC Score: 0.7337\n",
      "Recall Score: 0.3856\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Recall Score: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['auto_payment'].fillna(0, inplace=True)\n",
    "df_test['call_drops'].fillna(0, inplace=True)\n",
    "df_test['tenure'] = df_test['tenure'].fillna(tenure_median)\n",
    "df_test['data_usage'] = df_test['data_usage'].fillna(data_usage_median)\n",
    "df_test['monthly_charge'] = df_test['monthly_charge'].fillna(monthly_charge_median)\n",
    "df_test['avg_call_duration'] = df_test.groupby(\"service_type\")[\"avg_call_duration\"].transform(\"mean\")\n",
    "df_test[\"avg_call_duration\"] = df_test[\"avg_call_duration\"].fillna(0)\n",
    "df_test['roaming_usage'] = df_test['roaming_usage'].fillna(roaming_usage_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.get_dummies(df_test, columns=['service_type'], drop_first=False)\n",
    "df_test.drop(['id', 'apps'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== TEST SET METRİKLERİ ====\n",
      "True Positives (TP): 10402\n",
      "True Negatives (TN): 1683272\n",
      "False Positives (FP): 289646\n",
      "False Negatives (FN): 16680\n",
      "Recall: 0.3841\n",
      "F1 Score: 0.0636\n",
      "ROC AUC Score: 0.7348\n"
     ]
    }
   ],
   "source": [
    "# Test setine log dönüşümü uygula\n",
    "for col in ['avg_top_up_count', 'monthly_charge', 'tenure', 'age']:\n",
    "    df_test[col] = np.log1p(df_test[col])\n",
    "\n",
    "X_test_set = df_test.drop(columns=[\"churn\"])\n",
    "y_test_set = df_test[\"churn\"]\n",
    "\n",
    "y_pred_test = model.predict(X_test_set)\n",
    "y_pred_proba_test = model.predict_proba(X_test_set)[:, 1]\n",
    "\n",
    "conf_matrix_test = confusion_matrix(y_test_set, y_pred_test)\n",
    "\n",
    "TP_test = conf_matrix_test[1, 1]\n",
    "TN_test = conf_matrix_test[0, 0]\n",
    "FP_test = conf_matrix_test[0, 1]\n",
    "FN_test = conf_matrix_test[1, 0]\n",
    "\n",
    "recall_test = recall_score(y_test_set, y_pred_test)\n",
    "f1_test = f1_score(y_test_set, y_pred_test)\n",
    "roc_auc_test = roc_auc_score(y_test_set, y_pred_proba_test)\n",
    "\n",
    "print(\"==== TEST SET METRİKLERİ ====\")\n",
    "print(f\"True Positives (TP): {TP_test}\")\n",
    "print(f\"True Negatives (TN): {TN_test}\")\n",
    "print(f\"False Positives (FP): {FP_test}\")\n",
    "print(f\"False Negatives (FN): {FN_test}\")\n",
    "print(f\"Recall: {recall_test:.4f}\")\n",
    "print(f\"F1 Score: {f1_test:.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_test:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
